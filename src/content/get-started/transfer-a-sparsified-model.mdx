---
title: "Transfer a Sparsified Model"
metaTitle: "Transfer a Sparsified Model"
metaDescription: "Transfer a Sparsified Model to your dataset, enabling performant deep learning deployments with limited training"
githubURL: "https://github.com/neuralmagic/docs/blob/main/src/content/get-started/transfer-a-sparsified-model.mdx"
index: 3000
---

# Transfer a Sparsified Model

Sparse transfer learning enables an easy pathway for creating performant models on your datasets.
Like with dense transfer learning, sparse transfer learning works by creating a general architecture on a large dataset and then finetuning it onto another downstream dataset.
This process enables smaller models that can be deployed for cheaper and faster inferences without worrying about the hyperparameters involved in sparsifying a model from scratch.

SparseML contains convenient training CLIs that work with the SparseZoo to transfer sparsified models onto new datasets.
Once complete, the DeepSparse Engine is then used to reduce compute and accelerate CPU inference to GPU performance levels.

## Example Use Cases

The docs below walk through use cases leveraging SparseML for sparse transfer learning.

<LinkCards>
  <LinkCard href="./nlp-text-classification" heading="NLP Text Classification">
    Example transferring an NLP model to a text classification use case utilizing HuggingFace Transformers.
  </LinkCard>

  <LinkCard href="./cv-object-detection" heading="CV Object Detection">
    Example transferring an object detection model to a new dataset utilizing Ultralytics YOLOv5.
  </LinkCard>
</LinkCards>

## Other Use Cases

More documentation, models, use cases, and examples are continually being added.
If you don't see one you're interested in, search the [DeepSparse Github repo](https://github.com/neuralmagic/deepsparse), the [SparseML Github repo](https://github.com/neuralmagic/sparseml), the [SparseZoo website](https://sparsezoo.neuralmagic.com/), or ask in the [Neural Magic Slack](https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ).
