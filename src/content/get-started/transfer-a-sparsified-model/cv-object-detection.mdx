---
title: "CV Object Detection"
metaTitle: "Transfer a Sparsified Model for Object Detection"
metaDescription: "Transfer a Sparsified Object Detection Model to your dataset enabling performant deep learning deployments in a faster amount of time"
githubURL: "https://github.com/neuralmagic/docs/blob/main/src/content/get-started/transfer-a-sparse-model/object-detection.mdx"
index: 2000
---

# Transfer a Sparsified Model for Object Detection

SparseML enables advanced sparse transfer techniques packaged in convenient, recipe-powered CLIs and APIs.
The SparseZoo contains many different sparsified object detection models and recipes that plug directly into the SparseML CLIs and APIs.
The combination enables quick and easy creation of performant models with limited training and hyperparameter tuning.
The rest of the document walks through transferring a sparsified model onto your dataset for object detection.

## Transferring

The SparseZoo contains many different sparsified object detection models ready for sparse transfer.
A sparsified YOLOv5l model and sparse transfer recipe is used for this example.

```bash
zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned_quant-aggressive_95
```

The **sparseml.yolov5.train** command is now used to transfer the sparsified YOLOv5 model onto the VOC dataset for object detection.
After the command completes, the trained model will have a mAP@0.5 of around 0.80 on VOC and stored in the local `models/sparsified` directory.
To utilize your dataset, set up the appropriate image dataset structure and pass the path to the directory for the `--data` argument.

```bash
$ sparseml.yolov5.train \
    --project yolov5l \
    --name sparsified \
    --data VOC.yaml \
    --cfg models_v5.0/yolov5l.yaml \
    --weights zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned_quant-aggressive_95?recipe_type=transfer \
    --hyp data/hyps/hyp.finetune.yaml \
    --recipe recipes/yolov5.transfer_learn_pruned_quantized.md
```

## Exporting for Inference

With the sparsified model successfully trained, it is time to export it for inference.
The **sparseml.yolov5.export_onnx** command is used to export the training graph to a performant inference one.
After the command completes, a model.onnx file is created in `yolov5/sparsified` folder.
It is now ready for deployment with the DeepSparse Engine utilizing its pipelines.

```bash
$ sparseml.yolov5.export_onnx \
    --weights yolov5/sparsified/weights/best.pt\
    --dynamic
```
