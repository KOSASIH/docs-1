---
title: "Test a Model"
metaTitle: "Test a Model"
metaDescription: "Test a Model with the DeepSparse Engine to deploy for faster and cheaper inference on CPUs"
githubURL: "https://github.com/neuralmagic/docs/blob/main/src/content/get-started/test-a-model.mdx"
index: 2000
---

# Test a Model

DeepSparse supports sparsified and dense models by leveraging ONNX graph file definitions.
Trained models are first exported to an ONNX file which can then be loaded into the DeepSparse Engine to leverage its performance optimizations.
Performance checking is easily enabled through the DeepSparse benchmark CLI.

Additional functionality, such as pre-processing and post-processing, is enabled through DeepSparse Pipelines, which wrap around the model execution.
Building on top of the performance of the DeepSparse technology, pipelines allow for convenient, composable functionality such as multi-stream, bucketing, and dynamic shape, among others.

## Example Use Cases

The docs below walk through use cases leveraging DeepSparse for testing and benchmarking ONNX models for integrated use cases.

<LinkCards>
  <LinkCard href="./nlp-text-classification" heading="NLP Text Classification">
    Example pipelines and benchmarking for an NLP text classification use case utilizing HuggingFace Transformers.
  </LinkCard>

  <LinkCard href="./cv-object-detection" heading="CV Object Detection">
    Example pipelines and benchmarking for a CV object detection use case utilizing Ultralytics YOLOv5.
  </LinkCard>

  <LinkCard href="./custom-pipeline" heading="Custom Pipeline">
    Example for how to create a pipeline for a custom model utilizing the DeepSparse Engine.
  </LinkCard>
</LinkCards>

## Other Use Cases

More documentation, models, use cases, and examples are continually being added.
If you don't see one you're interested in, search the [DeepSparse Github repo](https://github.com/neuralmagic/deepsparse), the [SparseML Github repo](https://github.com/neuralmagic/sparseml), the [SparseZoo website](https://sparsezoo.neuralmagic.com/), or ask in the [Neural Magic Slack](https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ).
