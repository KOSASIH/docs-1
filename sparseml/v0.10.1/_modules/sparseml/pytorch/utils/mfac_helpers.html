

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>sparseml.pytorch.utils.mfac_helpers &mdash; SparseML 0.10.1.20220224 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/nm-theme-adjustment.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/clipboard.min.js"></script>
        <script src="../../../../_static/copybutton.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> SparseML
          

          
            
            <img src="../../../../_static/icon-sparseml.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.10
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">General</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/code.html">Sparsification Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/recipes.html">Sparsification Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../source/onnx_export.html">ONNX Export</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/sparseml.html">sparseml package</a></li>
</ul>
<p class="caption"><span class="caption-text">Connect Online</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discuss.neuralmagic.com/">Support, General Q&amp;A Forums</a></li>
<li class="toctree-l1"><a class="reference external" href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ">Deep Sparse Community Slack</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic">Neural Magic GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">SparseML</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>sparseml.pytorch.utils.mfac_helpers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for sparseml.pytorch.utils.mfac_helpers</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing,</span>
<span class="c1"># software distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Helper functions for performing Matrix-Free Approximate Curvature (M-FAC)</span>
<span class="sd">pruning.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">wraps</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Generator</span><span class="p">,</span>
    <span class="n">Iterable</span><span class="p">,</span>
    <span class="n">Iterator</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Module</span>
<span class="kn">from</span> <span class="nn">torch.nn.parallel.parallel_apply</span> <span class="kn">import</span> <span class="n">parallel_apply</span>

<span class="kn">import</span> <span class="nn">GPUtil</span>


<span class="n">_LOGGER</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
<span class="n">BYTES_IN_MIB</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">**</span> <span class="mi">2</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;GradSampler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;MFACOptions&quot;</span><span class="p">,</span>
    <span class="s2">&quot;FisherInverse&quot;</span><span class="p">,</span>
    <span class="s2">&quot;FisherInverseFast&quot;</span><span class="p">,</span>
    <span class="s2">&quot;FisherInverseFastBlock&quot;</span><span class="p">,</span>
    <span class="s2">&quot;FisherInverseFastPageSwap&quot;</span><span class="p">,</span>
    <span class="s2">&quot;FisherInverseFastSmallBlocks&quot;</span><span class="p">,</span>
    <span class="s2">&quot;compute_hessian_inv&quot;</span><span class="p">,</span>
<span class="p">]</span>


<div class="viewcode-block" id="GradSampler"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.GradSampler">[docs]</a><span class="k">class</span> <span class="nc">GradSampler</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for computing gradient samples for a Model given a sample data loader and</span>
<span class="sd">    loss function.</span>

<span class="sd">    :param data_loader: iterator of data samples to use as model inputs and their loss</span>
<span class="sd">        targets. items must be tuples of</span>
<span class="sd">        (forward_args: List, forward_kwargs: Dict, loss_targets: Any)</span>
<span class="sd">        where the forward pass will be outputs = model(*forward_args, **forward_kwargs)</span>
<span class="sd">        and loss will be loss = loss_fn(outputs, loss_targets)</span>
<span class="sd">    :param loss_fn: function to be called on model outputs to compute the loss at</span>
<span class="sd">        each step</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data_loader</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Any</span><span class="p">],</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;data_loader for GradSampler must be Iterable, received object of &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;loss_fn for GradSampler must be callable, given input &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;with type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_data_loader</span> <span class="o">=</span> <span class="n">data_loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>

<div class="viewcode-block" id="GradSampler.iter_module_backwards"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.GradSampler.iter_module_backwards">[docs]</a>    <span class="k">def</span> <span class="nf">iter_module_backwards</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param module: module to compute gradients for</span>
<span class="sd">        :param num_grads: number of gradient samples to compute</span>
<span class="sd">        :return: generator that yields after every gradient is computed with the index</span>
<span class="sd">            of the gradient sample number</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">computed_grads</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">while</span> <span class="n">computed_grads</span> <span class="o">&lt;</span> <span class="n">num_grads</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">forward_args</span><span class="p">,</span> <span class="n">forward_kwargs</span><span class="p">,</span> <span class="n">loss_target</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_loader</span><span class="p">:</span>
                <span class="n">module</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="c1"># run sample forward and backwards pass</span>
                <span class="n">model_outputs</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="o">*</span><span class="n">forward_args</span><span class="p">,</span> <span class="o">**</span><span class="n">forward_kwargs</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span><span class="p">(</span><span class="n">model_outputs</span><span class="p">,</span> <span class="n">loss_target</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

                <span class="c1"># yield so gradients can be collected</span>
                <span class="n">computed_grads</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">yield</span> <span class="n">computed_grads</span>

                <span class="k">if</span> <span class="n">computed_grads</span> <span class="o">&gt;=</span> <span class="n">num_grads</span><span class="p">:</span>
                    <span class="k">break</span>
        <span class="n">module</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="MFACOptions"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.MFACOptions">[docs]</a><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">MFACOptions</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Options for running the Matrix-Free Approxmiate Curvature (M-FAC) algorithm</span>

<span class="sd">    :param num_grads: number of gradients to store in buffer for Fisher computation.</span>
<span class="sd">        can be an int where that constant value will be used throughout pruning or a</span>
<span class="sd">        dictionary of float sparsity values to the number of gradients that should be</span>
<span class="sd">        stored when that sparsity level (between 0.0 and 1.0) is reached. If a</span>
<span class="sd">        dictionary, then 0.0 must be included as a key for the base number of gradients</span>
<span class="sd">        to store (i.e. {0: 64, 0.5: 128, 0.75: 256}). Default is 64</span>
<span class="sd">    :param damp: dampening factor, default is 1e-5</span>
<span class="sd">    :param grads_device: device to store the gradient buffer on. Default is &quot;cpu&quot;</span>
<span class="sd">    :param fisher_block_size: optional value to enable blocked computation of the</span>
<span class="sd">        Fisher matrix. Blocks will be formed consecutively along the diagonal. If</span>
<span class="sd">        None, blocked computation is not used. Default is 2000</span>
<span class="sd">    :param num_pages: number of pages to break the gradient samples into for GPU</span>
<span class="sd">        computation. Only available when blocked computation is not enabled.</span>
<span class="sd">        Default is 1</span>
<span class="sd">    :param available_gpus: list of GPU device names to perform computation on. Default</span>
<span class="sd">        is empty</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">num_grads</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">damp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span>
    <span class="n">grads_device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="n">fisher_block_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2000</span>
    <span class="n">num_pages</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># break computation into pages when block size is None</span>
    <span class="n">available_gpus</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">)</span>

<div class="viewcode-block" id="MFACOptions.get_num_grads_for_sparsity"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.MFACOptions.get_num_grads_for_sparsity">[docs]</a>    <span class="k">def</span> <span class="nf">get_num_grads_for_sparsity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_grads</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_grads</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sparsity</span><span class="p">,</span> <span class="n">List</span><span class="p">):</span>
            <span class="n">sparsity</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sparsity</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">sparsity</span><span class="p">)</span>

        <span class="n">sparsity_thresholds</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_grads</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">key</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">key</span><span class="p">)))</span>
        <span class="k">if</span> <span class="mf">0.0</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sparsity_thresholds</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Dictionary of sparsity thresholds to number of grads given for &quot;</span>
                <span class="s2">&quot;MFACOptions.num_grads, but 0 not included as a sparsity threshold. &quot;</span>
                <span class="s2">&quot;0.0 must be included as a sparsity threshold. Given thresholds &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sparsity_thresholds</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="p">(</span>
            <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">sparsity_thresholds</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">float</span><span class="p">(</span><span class="n">sparsity_thresholds</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">sparsity</span>
        <span class="p">):</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_grads</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_grads</span><span class="p">[</span><span class="n">sparsity_thresholds</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span></div></div>


<div class="viewcode-block" id="FisherInverse"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverse">[docs]</a><span class="k">class</span> <span class="nc">FisherInverse</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class for working with the inverse Fisher information matrix. Storing</span>
<span class="sd">    the full matrix is not a requirement.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="FisherInverse.diag"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverse.diag">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: the entries along the diagonal entries of the inverse Fisher matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="FisherInverse.mul"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverse.mul">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">mul</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param x: tensor to multiply with the inverse Fisher matrix</span>
<span class="sd">        :return: the matrix multiplied value of x and the inverse Fisher matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="FisherInverseFast"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFast">[docs]</a><span class="k">class</span> <span class="nc">FisherInverseFast</span><span class="p">(</span><span class="n">FisherInverse</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base implementation of computing the inverse Fisher matrix values based on the</span>
<span class="sd">    M-FAC paper. Takes O(d * m) memory and O(d * m^2) time to initialize where d</span>
<span class="sd">    is the number of parameters and m is the number of gradient samples</span>

<span class="sd">    :param grads: tensor of gradient samples to compute the inverse Fisher product</span>
<span class="sd">        with. Dimension should be (num_samples, num_parameters)</span>
<span class="sd">    :param damp: the dampening factor. Default is 1e-5</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">damp</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">damp</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span> <span class="o">=</span> <span class="n">grads</span>  <span class="c1"># placeholder for grads^T * H^-1 * grads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
        <span class="p">)</span>

        <span class="n">grad_sample</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">*</span> <span class="n">grad_sample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span> <span class="o">+</span> <span class="n">grad_sample</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>

        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">):</span>
            <span class="n">grad_sample</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">*</span> <span class="n">grad_sample</span>
            <span class="n">mul</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[:</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">grad_sample</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[:</span><span class="n">idx</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-=</span> <span class="n">mul</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[:</span><span class="n">idx</span><span class="p">,</span> <span class="p">:])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span> <span class="o">+</span> <span class="n">grad_sample</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:])</span>

<div class="viewcode-block" id="FisherInverseFast.diag"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFast.diag">[docs]</a>    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: the entries along the diagonal entries of the inverse Fisher matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">):</span>
            <span class="n">res</span> <span class="o">-=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="FisherInverseFast.mul"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFast.mul">[docs]</a>    <span class="k">def</span> <span class="nf">mul</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param x: tensor to multiply with the inverse Fisher matrix</span>
<span class="sd">        :return: the matrix multiplied value of x and the inverse Fisher matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">*</span> <span class="n">x</span>
        <span class="n">mul</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span>
        <span class="n">res</span> <span class="o">-=</span> <span class="n">mul</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="FisherInverseFast.to"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFast.to">[docs]</a>    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param device: device to move intermediate results to</span>
<span class="sd">        :return: device movement done in place, returns a copy of this object as well</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># in-place</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="k">return</span> <span class="bp">self</span></div></div>


<div class="viewcode-block" id="FisherInverseFastBlock"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastBlock">[docs]</a><span class="k">class</span> <span class="nc">FisherInverseFastBlock</span><span class="p">(</span><span class="n">FisherInverse</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of computing the inverse Fisher matrix values based on the</span>
<span class="sd">    M-FAC paper using a given block size to break up computation. Individual</span>
<span class="sd">    blocks must fit into GPU memory.</span>

<span class="sd">    :param grads: tensor of gradient samples to compute the inverse Fisher product</span>
<span class="sd">        with. Dimension should be (num_samples, num_parameters)</span>
<span class="sd">    :param block_size: size of blocks to form along diagonal of the Fisher matrix</span>
<span class="sd">    :param damp: the dampening factor. Default is 1e-5</span>
<span class="sd">    :param devices: list of GPU device ids to use for computation. Default is to use cpu</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">damp</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span> <span class="o">=</span> <span class="n">block_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_devices</span> <span class="o">=</span> <span class="n">devices</span> <span class="ow">or</span> <span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_fisher_inv_blocks</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Starting FisherInverseFastBlock&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">block_start_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">grads</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span><span class="p">):</span>
            <span class="n">block</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">grads</span><span class="p">[:,</span> <span class="n">block_start_idx</span> <span class="p">:</span> <span class="p">(</span><span class="n">block_start_idx</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span><span class="p">)]</span>
                <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">fisher_inv_block</span> <span class="o">=</span> <span class="n">FisherInverseFast</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">damp</span><span class="o">=</span><span class="n">damp</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fisher_inv_blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fisher_inv_block</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
            <span class="k">del</span> <span class="n">block</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;FisherInverseFastBlock H^-1 Calculation Complete&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="FisherInverseFastBlock.diag"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastBlock.diag">[docs]</a>    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: the entries along the diagonal entries of the inverse Fisher matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">fisher_inv_block</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fisher_inv_blocks</span><span class="p">):</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">[</span><span class="n">idx</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">)]</span>
            <span class="n">fisher_inv_block</span> <span class="o">=</span> <span class="n">fisher_inv_block</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fisher_inv_block</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
            <span class="c1"># free GPU mem</span>
            <span class="n">fisher_inv_block</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">res</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span></div>

<div class="viewcode-block" id="FisherInverseFastBlock.mul"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastBlock.mul">[docs]</a>    <span class="k">def</span> <span class="nf">mul</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param x: tensor to multiply with the inverse Fisher matrix</span>
<span class="sd">        :return: the matrix multiplied value of x and the inverse Fisher matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">fisher_inv_block</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fisher_inv_blocks</span><span class="p">):</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">[</span><span class="n">idx</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">)]</span>
            <span class="n">fisher_inv_block</span> <span class="o">=</span> <span class="n">fisher_inv_block</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">x_block</span> <span class="o">=</span> <span class="n">x</span><span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span> <span class="o">*</span> <span class="n">idx</span><span class="p">)</span> <span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="n">device</span>
            <span class="p">)</span>
            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fisher_inv_block</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x_block</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>

            <span class="c1"># free GPU mem</span>
            <span class="n">fisher_inv_block</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">res</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="FisherInverseFastPageSwap"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastPageSwap">[docs]</a><span class="k">class</span> <span class="nc">FisherInverseFastPageSwap</span><span class="p">(</span><span class="n">FisherInverse</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of computing the inverse Fisher matrix values based on the</span>
<span class="sd">    M-FAC paper using a given page size to break up computation across samples.</span>
<span class="sd">    Pages of gradients must fit into GPU memory.</span>

<span class="sd">    :param grads: tensor of gradient samples to compute the inverse Fisher product</span>
<span class="sd">        with. Dimension should be (num_samples, num_parameters)</span>
<span class="sd">    :param damp: the dampening factor. Default is 1e-5</span>
<span class="sd">    :param num_pages: number of pages to break gradient samples into. the number of</span>
<span class="sd">        gradients must be divisible by num_pages</span>
<span class="sd">    :param devices: list of GPU device ids to use for computation. Default is to use cpu</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">damp</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">num_pages</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">(),</span> <span class="p">(</span>
            <span class="s2">&quot;CUDA enabled device not available, &quot;</span>
            <span class="s2">&quot;but is required for using FisherInverseFastPageSwap&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_devices</span> <span class="o">=</span> <span class="n">devices</span> <span class="ow">or</span> <span class="p">[</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># for computations that fit on single GPU</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">damp</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span> <span class="o">&lt;</span> <span class="n">num_pages</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;num_grads cannot be smaller than num_pages&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span> <span class="o">%</span> <span class="n">num_pages</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;num_grads </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="si">}</span><span class="s2"> must be divisible by &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;num_pages </span><span class="si">{</span><span class="n">num_pages</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span> <span class="o">//</span> <span class="n">num_pages</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_params_per_device</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">)))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span> <span class="o">=</span> <span class="n">grads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="c1"># compute fisher inverse for first page across all GPUs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_comp_first_page</span><span class="p">()</span>

        <span class="c1"># run updates to fisher inverse on main GPU for remaining pages</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fisher_update_buffer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">page_offset</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_comp_page</span><span class="p">(</span><span class="n">page_offset</span><span class="p">)</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fisher_update_buffer</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span><span class="p">)</span>

<div class="viewcode-block" id="FisherInverseFastPageSwap.diag"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastPageSwap.diag">[docs]</a>    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: the entries along the diagonal entries of the inverse Fisher matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">page_offset</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">):</span>
            <span class="n">hinv_g_page</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span>
                <span class="n">page_offset</span> <span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span> <span class="o">+</span> <span class="n">page_offset</span><span class="p">),</span> <span class="p">:</span>
            <span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">page_sample_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">):</span>
                <span class="n">res</span> <span class="o">-=</span> <span class="p">(</span><span class="n">hinv_g_page</span><span class="p">[</span><span class="n">page_sample_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span>
                    <span class="n">page_sample_idx</span> <span class="o">+</span> <span class="n">page_offset</span>
                <span class="p">]</span>
            <span class="k">del</span> <span class="n">hinv_g_page</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="FisherInverseFastPageSwap.mul"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastPageSwap.mul">[docs]</a>    <span class="k">def</span> <span class="nf">mul</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param x: tensor to multiply with the inverse Fisher matrix</span>
<span class="sd">        :return: the matrix multiplied value of x and the inverse Fisher matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span><span class="p">)</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">*</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">page_offset</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">):</span>
            <span class="n">hinv_g_page</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span>
                <span class="n">page_offset</span> <span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span> <span class="o">+</span> <span class="n">page_offset</span><span class="p">),</span> <span class="p">:</span>
            <span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span><span class="p">)</span>
            <span class="n">mul</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">hinv_g_page</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span><span class="n">page_offset</span> <span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span> <span class="o">+</span> <span class="n">page_offset</span><span class="p">)]</span>
            <span class="p">)</span>
            <span class="n">res</span> <span class="o">-=</span> <span class="n">mul</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hinv_g_page</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">hinv_g_page</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res</span></div>

    <span class="k">def</span> <span class="nf">_comp_first_page</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># move first page value to devices across GPUs</span>
        <span class="k">def</span> <span class="nf">_get_first_page_on_device</span><span class="p">(</span><span class="n">params_idx</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span>
                <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">,</span>
                <span class="n">params_idx</span> <span class="p">:</span> <span class="p">(</span><span class="n">params_idx</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_per_device</span><span class="p">),</span>
            <span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">first_page_hinv_g_dist</span> <span class="o">=</span> <span class="n">parallel_apply</span><span class="p">(</span>
            <span class="p">[</span><span class="n">_get_first_page_on_device</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">),</span>
            <span class="nb">list</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_per_device</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">)</span>
            <span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># compute value for first gradient sample</span>
        <span class="k">def</span> <span class="nf">_process_first_sample</span><span class="p">(</span><span class="n">first_page_hinv_g</span><span class="p">):</span>
            <span class="n">first_grad</span> <span class="o">=</span> <span class="n">first_page_hinv_g</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">first_page_hinv_g</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">*</span> <span class="n">first_grad</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">first_grad</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">first_page_hinv_g</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="n">parallel_apply</span><span class="p">(</span>
            <span class="p">[</span><span class="n">_process_first_sample</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">),</span>
            <span class="n">first_page_hinv_g_dist</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span>

        <span class="k">for</span> <span class="n">sample_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">):</span>
            <span class="c1"># update the other page gradients in parallel with two steps</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mul_tmp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">sample_idx</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_sample_grads_dist</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">)</span>  <span class="c1"># type: List[Tensor]</span>

            <span class="k">def</span> <span class="nf">_calc_mul_update_dist</span><span class="p">(</span><span class="n">device_idx</span><span class="p">,</span> <span class="n">hinv_g_shard</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_sample_grads_dist</span><span class="p">[</span><span class="n">device_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">hinv_g_shard</span><span class="p">[</span>
                    <span class="n">sample_idx</span><span class="p">,</span> <span class="p">:</span>
                <span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">hinv_g_shard</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_grads_dist</span><span class="p">[</span><span class="n">device_idx</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_mul_tmp</span> <span class="o">+=</span> <span class="p">(</span>
                    <span class="n">hinv_g_shard</span><span class="p">[:</span><span class="n">sample_idx</span><span class="p">,</span> <span class="p">:]</span>
                    <span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sample_grads_dist</span><span class="p">[</span><span class="n">device_idx</span><span class="p">])</span>
                    <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="n">parallel_apply</span><span class="p">(</span>
                <span class="p">[</span><span class="n">_calc_mul_update_dist</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">),</span>
                <span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">first_page_hinv_g_dist</span><span class="p">)),</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mul_tmp</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[:</span><span class="n">sample_idx</span><span class="p">]</span>

            <span class="k">def</span> <span class="nf">_apply_mul_update_dist</span><span class="p">(</span><span class="n">device_idx</span><span class="p">,</span> <span class="n">hinv_g_shard</span><span class="p">):</span>
                <span class="n">hinv_g_shard</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mul_tmp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                    <span class="n">hinv_g_shard</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hinv_g_shard</span><span class="p">[:</span><span class="n">sample_idx</span><span class="p">,</span> <span class="p">:])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_sample_grads_dist</span><span class="p">[</span><span class="n">device_idx</span><span class="p">]</span>
                    <span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">hinv_g_shard</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">,</span> <span class="p">:])</span>
                    <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="n">parallel_apply</span><span class="p">(</span>
                <span class="p">[</span><span class="n">_apply_mul_update_dist</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">),</span>
                <span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">first_page_hinv_g_dist</span><span class="p">)),</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mul_tmp</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_grads_dist</span>

        <span class="k">def</span> <span class="nf">_update_main_hinv_g</span><span class="p">(</span><span class="n">shard_param_idx</span><span class="p">,</span> <span class="n">hinv_g_shard</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span>
                <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">,</span>
                <span class="n">shard_param_idx</span> <span class="p">:</span> <span class="p">(</span><span class="n">shard_param_idx</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_per_device</span><span class="p">),</span>
            <span class="p">]</span> <span class="o">=</span> <span class="n">hinv_g_shard</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

        <span class="n">parallel_apply</span><span class="p">(</span>
            <span class="p">[</span><span class="n">_update_main_hinv_g</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">first_page_hinv_g_dist</span><span class="p">),</span>
            <span class="nb">list</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span>
                    <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params_per_device</span><span class="p">),</span>
                    <span class="n">first_page_hinv_g_dist</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">),</span>
        <span class="p">)</span>
        <span class="k">del</span> <span class="n">first_page_hinv_g_dist</span>

    <span class="k">def</span> <span class="nf">_comp_page</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">page_offset</span><span class="p">):</span>
        <span class="c1"># update fisher update buffer</span>
        <span class="k">for</span> <span class="n">prev_page_offset</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">page_offset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">):</span>
            <span class="n">prev_page_hinv_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span>
                <span class="n">prev_page_offset</span> <span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span> <span class="o">+</span> <span class="n">prev_page_offset</span><span class="p">),</span> <span class="p">:</span>
            <span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">page_sample_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">):</span>
                <span class="n">grad_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span><span class="n">page_sample_idx</span> <span class="o">+</span> <span class="n">page_offset</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span>
                <span class="p">)</span>
                <span class="n">mul</span> <span class="o">=</span> <span class="n">prev_page_hinv_g</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">grad_sample</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span>
                    <span class="n">prev_page_offset</span> <span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span> <span class="o">+</span> <span class="n">prev_page_offset</span><span class="p">)</span>
                <span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span><span class="p">)</span>
                <span class="n">mul</span> <span class="o">=</span> <span class="n">mul</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">prev_page_hinv_g</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">prev_page_offset</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_fisher_update_buffer</span><span class="p">[</span><span class="n">page_sample_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">*</span> <span class="n">grad_sample</span> <span class="o">-</span> <span class="n">mul</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_fisher_update_buffer</span><span class="p">[</span><span class="n">page_sample_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-=</span> <span class="n">mul</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">prev_page_hinv_g</span>

        <span class="c1"># move buffer to main GPU and update the fisher inv state</span>
        <span class="n">fisher_inv_buf_gpu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fisher_update_buffer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span><span class="p">)</span>

        <span class="n">grad_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span><span class="n">page_offset</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span><span class="n">page_offset</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span> <span class="o">+</span> <span class="n">grad_sample</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
            <span class="n">fisher_inv_buf_gpu</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">page_sample_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span><span class="p">):</span>
            <span class="n">grad_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span><span class="n">page_sample_idx</span> <span class="o">+</span> <span class="n">page_offset</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span><span class="p">)</span>
            <span class="n">mul</span> <span class="o">=</span> <span class="n">fisher_inv_buf_gpu</span><span class="p">[:</span><span class="n">page_sample_idx</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
                <span class="n">grad_sample</span>
            <span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span><span class="n">page_offset</span> <span class="p">:</span> <span class="p">(</span><span class="n">page_sample_idx</span> <span class="o">+</span> <span class="n">page_offset</span><span class="p">)]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_gpu0</span>
            <span class="p">)</span>
            <span class="n">fisher_inv_buf_gpu</span><span class="p">[</span><span class="n">page_sample_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-=</span> <span class="n">mul</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
                <span class="n">fisher_inv_buf_gpu</span><span class="p">[:</span><span class="n">page_sample_idx</span><span class="p">,</span> <span class="p">:]</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_denom</span><span class="p">[</span>
                <span class="n">page_sample_idx</span> <span class="o">+</span> <span class="n">page_offset</span>
            <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span> <span class="o">+</span> <span class="n">grad_sample</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span>
                <span class="n">fisher_inv_buf_gpu</span><span class="p">[</span><span class="n">page_sample_idx</span><span class="p">,</span> <span class="p">:]</span>
            <span class="p">)</span>

        <span class="c1"># update main tensor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hinv_g</span><span class="p">[</span>
            <span class="n">page_offset</span> <span class="p">:</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_samples_per_page</span> <span class="o">+</span> <span class="n">page_offset</span><span class="p">),</span> <span class="p">:</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">fisher_inv_buf_gpu</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">fisher_inv_buf_gpu</span></div>


<div class="viewcode-block" id="FisherInverseFastSmallBlocks"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastSmallBlocks">[docs]</a><span class="k">class</span> <span class="nc">FisherInverseFastSmallBlocks</span><span class="p">(</span><span class="n">FisherInverse</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of computing the inverse Fisher matrix values based on the</span>
<span class="sd">    M-FAC paper that is optimized for speed for small block sizes</span>

<span class="sd">    :param grads: tensor of gradient samples to compute the inverse Fisher product</span>
<span class="sd">        with. Dimension should be (num_samples, num_parameters)</span>
<span class="sd">    :param block_size: size of blocks to form along diagonal of the Fisher matrix</span>
<span class="sd">    :param damp: the dampening factor. Default is 1e-5</span>
<span class="sd">    :param devices: list of GPU device ids to use for computation. Default is to use cpu</span>
<span class="sd">    :param alpha: alpha value for add step</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">grads</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">block_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">damp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">devices</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_element_size</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">element_size</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span> <span class="o">=</span> <span class="n">block_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_devices</span> <span class="o">=</span> <span class="n">devices</span> <span class="ow">or</span> <span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span> <span class="o">=</span> <span class="n">damp</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span> <span class="o">/</span> <span class="n">block_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_devices</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">block_mem</span> <span class="o">=</span> <span class="n">_block_memory_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_element_size</span><span class="p">)</span>

        <span class="n">cpu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hinv</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">grads</span><span class="p">,</span> <span class="n">block_mem</span><span class="o">=</span><span class="n">block_mem</span><span class="p">,</span> <span class="n">cpu</span><span class="o">=</span><span class="n">cpu</span><span class="p">)</span>

<div class="viewcode-block" id="FisherInverseFastSmallBlocks.block_wise_decorator"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastSmallBlocks.block_wise_decorator">[docs]</a>    <span class="k">def</span> <span class="nf">block_wise_decorator</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
        <span class="nd">@wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapper_blocked</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
            <span class="n">block_mem</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">safety_margin</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
            <span class="n">cpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Wraps the most memory intensive Fisher computations in a memory-aware block</span>
<span class="sd">            allocation function. The decorator will allocate a number of blocks which</span>
<span class="sd">            will maximize GPU memory utilization (if GPUs are utilized) with a safety</span>
<span class="sd">            margin</span>

<span class="sd">            Note: currently each device is called in sequence. There is no clear benefit</span>
<span class="sd">            to this regime over simply re-using one device, but it may lend to easier</span>
<span class="sd">            parallelization in the future and it upholds the M-FAC &quot;available_devices&quot;</span>
<span class="sd">            parameter expected behavior.</span>

<span class="sd">            :param tensor: The input tensor for func, the fisher computation function</span>
<span class="sd">            :param block_mem: The amount of memory needed (in bytes) for the</span>
<span class="sd">            computation of one block</span>
<span class="sd">            :param safety_margin: The total number of blocks allocated per device is</span>
<span class="sd">            (1 - safety_margin)*max_blocks, where max_blocks is the maximum that could</span>
<span class="sd">            fit on the device at this time</span>
<span class="sd">            :param cpu: When true all computation is done on the CPU, without the</span>
<span class="sd">            memory-aware logic</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="n">cpu</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks</span><span class="p">]</span>
                <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>  <span class="c1"># Process all the blocks in one call</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_remaining_blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_device_suite_calls</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Number of calls to the full set of gpus</span>
                <span class="c1"># Calculate free memory available on each device</span>
                <span class="n">free_device_memory</span> <span class="o">=</span> <span class="n">_get_free_gpu_memory</span><span class="p">(</span>
                    <span class="n">_cuda_list_to_idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">_remaining_blocks</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Allocate blocks based on device memory, until either all blocks</span>
                    <span class="c1"># are allocated or all gpus have been assigned for this iteration</span>
                    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">device</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="nb">min</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_remaining_blocks</span><span class="p">,</span>
                                <span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span>
                                    <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">safety_margin</span><span class="p">)</span>
                                    <span class="o">*</span> <span class="n">free_device_memory</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                                    <span class="o">*</span> <span class="n">BYTES_IN_MIB</span>
                                    <span class="o">/</span> <span class="n">block_mem</span>
                                <span class="p">),</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_remaining_blocks</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Allocating </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> blocks&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;to device </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_remaining_blocks</span><span class="si">}</span><span class="s2"> blocks&quot;</span>
                            <span class="s2">&quot;remaining&quot;</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_remaining_blocks</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="k">break</span>

                    <span class="c1"># Iterate through each device and perform computation</span>
                    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">device</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">):</span>
                        <span class="n">call_idx</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_suite_calls</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_devices</span>
                        <span class="k">if</span> <span class="n">call_idx</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">):</span>
                            <span class="k">break</span>
                        <span class="n">func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">call_idx</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">_device_suite_calls</span> <span class="o">+=</span> <span class="mi">1</span>

                    <span class="c1"># At the end of each iteration the net memory change should be 0</span>
                    <span class="c1"># If the free memory decreases, throw a warning in debug mode</span>
                    <span class="n">prev_free_memory</span> <span class="o">=</span> <span class="n">free_device_memory</span>
                    <span class="n">free_device_memory</span> <span class="o">=</span> <span class="n">_get_free_gpu_memory</span><span class="p">(</span>
                        <span class="n">_cuda_list_to_idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">free_device_memory</span><span class="p">)):</span>
                        <span class="k">if</span> <span class="n">free_device_memory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">prev_free_memory</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                            <span class="n">memory_diff</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="n">prev_free_memory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">free_device_memory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                            <span class="p">)</span> <span class="o">/</span> <span class="n">BYTES_IN_MIB</span>
                            <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;WARNING - GPU memory not cleanly freed.&quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;Found </span><span class="si">{</span><span class="n">memory_diff</span><span class="si">}</span><span class="s2"> less MiB&quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;since the last iteration&quot;</span>
                            <span class="p">)</span>

                <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks</span><span class="p">:</span>
                    <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="s2">&quot;WARNING - Number of blocks processed does not equal to total&quot;</span>
                        <span class="s2">&quot;numver of blocks.&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Total blocks - </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Processed blocks - </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

        <span class="k">return</span> <span class="n">wrapper_blocked</span></div>

<div class="viewcode-block" id="FisherInverseFastSmallBlocks.hinv"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastSmallBlocks.hinv">[docs]</a>    <span class="nd">@block_wise_decorator</span>
    <span class="k">def</span> <span class="nf">hinv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">call_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the H^-1 and compute its result for the given device.</span>

<span class="sd">        :param grads: The sampled gradients used for H^-1 computation</span>
<span class="sd">        :param call_idx: The index of the number of single-device calls</span>
<span class="sd">        :param device: the device on which to perform the computations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># initialize H_invs on each device</span>
        <span class="n">num_blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">[</span><span class="n">call_idx</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_init_hinv</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initialized H^-1 for </span><span class="si">{</span><span class="n">num_blocks</span><span class="si">}</span><span class="s2"> blocks on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># As a failsafe for a memory issue, try again with half the number of blocks</span>
        <span class="c1"># This condition has not been encountered in testing as of yet</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">error_msg</span><span class="p">:</span>
            <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">error_msg</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Initialization of H^-1 for </span><span class="si">{</span><span class="n">num_blocks</span><span class="si">}</span><span class="s2"> blocks on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2"> failed&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Retrying with </span><span class="si">{</span><span class="n">num_blocks</span><span class="o">//</span><span class="mi">2</span><span class="si">}</span><span class="s2"> blocks&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_init_hinv</span><span class="p">(</span><span class="n">num_blocks</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_damp</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">[</span><span class="n">call_idx</span><span class="p">]</span> <span class="o">//=</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_remaining_blocks</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">[</span><span class="n">call_idx</span><span class="p">]</span>
            <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Initialized H^-1 for </span><span class="si">{</span><span class="n">num_blocks</span><span class="o">//</span><span class="mi">2</span><span class="si">}</span><span class="s2"> blocks on </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;remaining blocks increased to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_remaining_blocks</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># build hinv_g values from grad samples</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;Calculating H^-1 with </span><span class="si">{self._num_samples}</span><span class="s2"> samples for call </span><span class="si">{call_idx}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">sample_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">device</span><span class="p">,</span> <span class="n">call_idx</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span><span class="p">[</span><span class="n">call_idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span><span class="p">[</span><span class="n">call_idx</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Finished H^-1 calculation and moved mat to CPU&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="FisherInverseFastSmallBlocks.diag"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastSmallBlocks.diag">[docs]</a>    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: the entries along the diagonal entries of the inverse Fisher matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">diag_slices</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="o">-</span><span class="mi">1</span>
            <span class="p">)</span>  <span class="c1"># move all to same device after computation</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">))</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">diag_slices</span><span class="p">)[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span><span class="p">]</span></div>

<div class="viewcode-block" id="FisherInverseFastSmallBlocks.mul"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastSmallBlocks.mul">[docs]</a>    <span class="k">def</span> <span class="nf">mul</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param x: tensor to multiply with the inverse Fisher matrix</span>
<span class="sd">        :return: the matrix multiplied value of x and the inverse Fisher matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mul_slices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">block_mem</span> <span class="o">=</span> <span class="n">_block_memory_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_element_size</span><span class="p">)</span>
        <span class="n">cpu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mul_blocked</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">block_mem</span><span class="o">=</span><span class="n">block_mem</span><span class="p">,</span> <span class="n">cpu</span><span class="o">=</span><span class="n">cpu</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mul_slices</span><span class="p">)[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_params</span><span class="p">]</span></div>

<div class="viewcode-block" id="FisherInverseFastSmallBlocks.mul_blocked"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.FisherInverseFastSmallBlocks.mul_blocked">[docs]</a>    <span class="nd">@block_wise_decorator</span>
    <span class="k">def</span> <span class="nf">mul_blocked</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">call_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param x: tensor to multiply with the inverse Fisher matrix</span>
<span class="sd">        :param call_idx: The index of the number of single-device calls</span>
<span class="sd">        :param device: the device on which to perform the computations</span>
<span class="sd">        :return: the matrix multiplied value of x and the inverse Fisher matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x_slice</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span>
            <span class="nb">int</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">[:</span><span class="n">call_idx</span><span class="p">])</span>
                <span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">[:</span> <span class="n">call_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
                <span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Get the H^-1 values corresponding to the number of blocks used here.</span>
        <span class="c1"># It&#39;s clunky compared to torch.cat()[idx], but avoids duplicating</span>
        <span class="c1"># the memory of H^-1</span>
        <span class="n">start_block</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">[:</span><span class="n">call_idx</span><span class="p">])</span>
        <span class="n">end_block</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span><span class="p">[:</span> <span class="n">call_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">t_hinv</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">tensor_start</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">tensor_end</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span><span class="p">:</span>
            <span class="n">tensor_end</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">start_block</span> <span class="o">&gt;</span> <span class="n">tensor_end</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">end_block</span> <span class="o">&lt;</span> <span class="n">tensor_end</span><span class="p">:</span>
                <span class="n">t_hinv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">tensor</span><span class="p">[</span><span class="n">start_block</span> <span class="o">-</span> <span class="n">tensor_start</span> <span class="p">:</span> <span class="n">end_block</span> <span class="o">-</span> <span class="n">tensor_start</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">t_hinv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor</span><span class="p">[</span><span class="n">start_block</span> <span class="o">-</span> <span class="n">tensor_start</span> <span class="p">:])</span>
                <span class="n">start_block</span> <span class="o">=</span> <span class="n">tensor_end</span>
            <span class="n">tensor_start</span> <span class="o">=</span> <span class="n">tensor_end</span>

        <span class="n">mul_slice</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">t_hinv</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">x_slice</span><span class="p">)</span>
            <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>  <span class="c1"># move all to same device after computation</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mul_slices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mul_slice</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_init_hinv</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">damp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># initialize hinv to num_blocks diagonal blocks of size blocksize</span>
        <span class="n">base_block</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span><span class="p">],</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">damp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">base_block</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">num_blocks</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grad_sample</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">call_idx</span><span class="p">):</span>
        <span class="c1"># add gradient sample into H_invs</span>
        <span class="n">num_params_per_device</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">num_blocks_device</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span>
            <span class="k">for</span> <span class="n">num_blocks_device</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks_per_device_call</span>
        <span class="p">]</span>

        <span class="n">grad_sample_slice</span> <span class="o">=</span> <span class="n">grad_sample</span><span class="p">[</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">num_params_per_device</span><span class="p">[:</span><span class="n">call_idx</span><span class="p">]))</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">num_params_per_device</span><span class="p">[:</span> <span class="n">call_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">grad_sample_slice</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># pad to block size</span>
            <span class="n">pad_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">grad_sample_slice</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span>
            <span class="p">)</span>
            <span class="n">grad_sample_slice</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">grad_sample_slice</span><span class="p">,</span> <span class="n">pad_vals</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">grad_sample</span><span class="o">.</span><span class="n">device</span><span class="p">)]</span>
            <span class="p">)</span>
        <span class="n">grads_blocked_device</span> <span class="o">=</span> <span class="n">grad_sample_slice</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">hinv_g_slice</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span><span class="p">[</span><span class="n">call_idx</span><span class="p">],</span> <span class="n">grads_blocked_device</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">denom</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_samples</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">grads_blocked_device</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">hinv_g_slice</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">hinv_g_slice</span> <span class="o">=</span> <span class="n">hinv_g_slice</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">idx_block</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span><span class="p">):</span>
            <span class="c1"># update h_inv calculation across block dims</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span><span class="p">[</span><span class="n">call_idx</span><span class="p">][:,</span> <span class="n">idx_block</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-=</span> <span class="n">hinv_g_slice</span> <span class="o">*</span> <span class="p">(</span>
                <span class="n">hinv_g_slice</span><span class="p">[:,</span> <span class="n">idx_block</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">denom</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_pad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="c1"># pad 1-d tensor to num_blocks * block_size</span>
        <span class="n">padded_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_blocks</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_block_size</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_hinvs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">padded_x</span><span class="p">[:</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">padded_x</span></div>


<div class="viewcode-block" id="compute_hessian_inv"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.optim.mask_pruning_scorer.compute_hessian_inv">[docs]</a><span class="k">def</span> <span class="nf">compute_hessian_inv</span><span class="p">(</span>
    <span class="n">grads</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mfac_options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MFACOptions</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FisherInverse</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Determine which FisherInverse algorithm to use.</span>

<span class="sd">    :param grads: tensor of gradient samples to compute the Hessian inverse</span>
<span class="sd">        representation with. Should have shape (num_samples, num_parameters)</span>
<span class="sd">    :param mfac_options: MFACOptions object specifying how to perform the computations</span>
<span class="sd">    :return: FisherInverse object with access to the diagonal multiplication of the</span>
<span class="sd">        Fisher approximation of the Hessian inverse</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">mfac_options</span><span class="p">:</span>
        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No M-FAC options found - using defaults&quot;</span><span class="p">)</span>
        <span class="n">mfac_options</span> <span class="o">=</span> <span class="n">MFACOptions</span><span class="p">()</span>
    <span class="c1"># The amount of memory required for the computation of one block is the main</span>
    <span class="c1"># decider in the FisherInverse algorithm to use</span>
    <span class="k">if</span> <span class="n">mfac_options</span><span class="o">.</span><span class="n">fisher_block_size</span><span class="p">:</span>
        <span class="n">block_mem_size</span> <span class="o">=</span> <span class="n">_block_memory_size</span><span class="p">(</span>
            <span class="n">block_size</span><span class="o">=</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">fisher_block_size</span><span class="p">,</span> <span class="n">element_size</span><span class="o">=</span><span class="n">grads</span><span class="o">.</span><span class="n">element_size</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Calculated Fisher block with size </span><span class="si">{</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">fisher_block_size</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;to occupy </span><span class="si">{</span><span class="n">block_mem_size</span><span class="si">}</span><span class="s2"> bytes/ </span><span class="si">{</span><span class="n">block_mem_size</span><span class="o">/</span><span class="n">BYTES_IN_MIB</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="s2">&quot;MiB in memory&quot;</span>
        <span class="p">)</span>

        <span class="n">free_device_mem</span> <span class="o">=</span> <span class="n">_get_free_gpu_memory</span><span class="p">(</span>
            <span class="n">_cuda_list_to_idx</span><span class="p">(</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">available_gpus</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;Free memory on devices:&quot;</span>
            <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">available_gpus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">: &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">free_device_mem</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">/</span><span class="n">BYTES_IN_MIB</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">free_device_mem</span><span class="p">))</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Determine which of the available gpus have enough free memory to host</span>
        <span class="c1"># the block computation</span>
        <span class="n">available_gpus</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">gpu</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">available_gpus</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">free_device_mem</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">block_mem_size</span> <span class="o">/</span> <span class="n">BYTES_IN_MIB</span>
        <span class="p">]</span>

        <span class="c1"># FisherInverseFastBlock works only in sequential mode. Unless only one block</span>
        <span class="c1"># or less can fit on the GPU, FisherInverseFastSmallBlocks should be used</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">available_gpus</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">free_device_mem</span><span class="p">:</span>
            <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using Small Block Fast Fisher Inverse Implementation&quot;</span><span class="p">)</span>
            <span class="n">_LOGGER</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="s2">&quot;Using the following devices for M-FAC:&quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">available_gpus</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">mfac_options</span><span class="o">.</span><span class="n">available_gpus</span> <span class="o">=</span> <span class="n">available_gpus</span>
            <span class="n">block_fisher_class</span> <span class="o">=</span> <span class="n">FisherInverseFastSmallBlocks</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Large block size detected - Using Fast Block Fisher Inverse &quot;</span>
                <span class="s2">&quot;Implementation&quot;</span>
            <span class="p">)</span>
            <span class="n">block_fisher_class</span> <span class="o">=</span> <span class="n">FisherInverseFastBlock</span>

        <span class="k">return</span> <span class="n">block_fisher_class</span><span class="p">(</span>
            <span class="n">grads</span><span class="p">,</span>
            <span class="n">mfac_options</span><span class="o">.</span><span class="n">fisher_block_size</span><span class="p">,</span>
            <span class="n">damp</span><span class="o">=</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">damp</span><span class="p">,</span>
            <span class="n">devices</span><span class="o">=</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">available_gpus</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">mfac_options</span><span class="o">.</span><span class="n">available_gpus</span> <span class="ow">or</span> <span class="n">mfac_options</span><span class="o">.</span><span class="n">num_pages</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">FisherInverseFastPageSwap</span><span class="p">(</span>
            <span class="n">grads</span><span class="p">,</span>
            <span class="n">damp</span><span class="o">=</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">damp</span><span class="p">,</span>
            <span class="n">num_pages</span><span class="o">=</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">num_pages</span><span class="p">,</span>
            <span class="n">devices</span><span class="o">=</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">available_gpus</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">FisherInverseFast</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">damp</span><span class="o">=</span><span class="n">mfac_options</span><span class="o">.</span><span class="n">damp</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_free_gpu_memory</span><span class="p">(</span>
    <span class="n">device_idx</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">clear_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get free memory available on device(s)</span>

<span class="sd">    Note: GPUtil and PyTorch may see different devices and device orders depending on</span>
<span class="sd">    the value of CUDA_VISIBLE_DEVICES. This function honors the PyTorch device view.</span>

<span class="sd">    :param device_idx: Devices to retrieve free memory for. If empty, will use</span>
<span class="sd">    all visible devices</span>
<span class="sd">    :param clear_cache: Whether to clear pytorch reserved memory before retrieving free</span>
<span class="sd">    memory. Leaving this flag on will result in a larger (and more accurate) free memory</span>
<span class="sd">    reading, but comes at a (small) cost to pytorch tensor allocation speed. In the case</span>
<span class="sd">    of very high frequency calls, it may be better to turn clear_cache off.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">device_idx</span><span class="p">:</span>
        <span class="n">device_idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">device_idx</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>  <span class="c1"># An empty list signals to use cpu</span>
    <span class="k">if</span> <span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;GPU device specified for M-FAC, but no GPUs&quot;</span>
                <span class="s2">&quot;were found in CUDA_VISIBLE_DEVICES&quot;</span>
            <span class="p">)</span>
        <span class="n">gpu_idx_all</span> <span class="o">=</span> <span class="p">[</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">gpu_idx</span> <span class="o">=</span> <span class="p">[</span><span class="n">gpu_idx_all</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">device_idx</span><span class="p">]</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">gpu_idx</span> <span class="o">=</span> <span class="n">device_idx</span>

    <span class="k">if</span> <span class="n">clear_cache</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="n">gpus_all</span> <span class="o">=</span> <span class="n">GPUtil</span><span class="o">.</span><span class="n">getGPUs</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">gpus_all</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">memoryFree</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">gpu_idx</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_cuda_list_to_idx</span><span class="p">(</span><span class="n">cuda_device_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert list of cuda device string names to indices.</span>
<span class="sd">    e.g. &quot;cuda:0&quot; -&gt; 0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="nb">int</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">isdigit</span><span class="p">,</span> <span class="n">device_str</span><span class="p">)))</span> <span class="k">for</span> <span class="n">device_str</span> <span class="ow">in</span> <span class="n">cuda_device_list</span>
    <span class="p">]</span>


<span class="k">def</span> <span class="nf">_block_memory_size</span><span class="p">(</span><span class="n">block_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">element_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate memory needed for H^-1 calculations of one block.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># B^2 * e_size - memory required for H^-1</span>
    <span class="c1"># 4*B * e_size - memory required for additional comp vectors</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">block_size</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">block_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">element_size</span>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 - present / Neuralmagic, Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the &#34;License&#34;).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v0.10.1
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../../../../v0.10.0/index.html">v0.10.0</a></dd>
      <dd><a href="mfac_helpers.html">v0.10.1</a></dd>
      <dd><a href="../../../../../v0.3.0/index.html">v0.3.0</a></dd>
      <dd><a href="../../../../../v0.3.1/index.html">v0.3.1</a></dd>
      <dd><a href="../../../../../v0.4.0/index.html">v0.4.0</a></dd>
      <dd><a href="../../../../../v0.5.0/index.html">v0.5.0</a></dd>
      <dd><a href="../../../../../v0.5.1/index.html">v0.5.1</a></dd>
      <dd><a href="../../../../../v0.6.0/index.html">v0.6.0</a></dd>
      <dd><a href="../../../../../v0.7.0/index.html">v0.7.0</a></dd>
      <dd><a href="../../../../../v0.8.0/index.html">v0.8.0</a></dd>
      <dd><a href="../../../../../v0.9.0/index.html">v0.9.0</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../../../../main/index.html">main</a></dd>
    </dl>
  </div>
</div>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-128364174-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>